{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruoyuz31/Coding-Practice/blob/main/TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA0rETRQZBON"
      },
      "source": [
        "# EE 508 Reading Assignment 2:\n",
        "You can access paper using this [link](https://arxiv.org/pdf/1704.04760.pdf). Please refer to this [guideline](http://ccr.sigcomm.org/online/files/p83-keshavA.pdf) on how to read a research paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-HWWv6kaxrx"
      },
      "source": [
        "### Q1: (1 Point)\n",
        "\n",
        "**Disallowed** list:\n",
        "- You **MAY NOT** collaborate with anyone else on this assignment. This means you cannot talk to anyone else about the assignment until after deadline.\n",
        "- You **MAY NOT** use ChatGPT and services like that\n",
        "\n",
        "**Allowed** list:\n",
        "- Notes including any slides from the class\n",
        "- The textbooks\n",
        "- The given paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0uD-nHbHuT"
      },
      "source": [
        "### A1:\n",
        "\n",
        "I affirm I have read these exam rules and will follow them. Failure to do so may subject me to sanctions including an F in the course.\n",
        "\n",
        "**Type your full name to affirm you have read the above statement:** Ruoyu Zhao\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzNWLVCLbcjq"
      },
      "source": [
        "----\n",
        "### Q2 Summary (24 Points):\n",
        "\n",
        "Summarize the main objectives and contributions of the paper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j5A4_Zfbpra"
      },
      "source": [
        "### A2:\n",
        "This paper's objective is to analyze the performance of Tensor Processing Unit in datacenter and compare it with the performance of GPU and CPU.\n",
        "\n",
        "The contributions are as follows:\n",
        "1. Introduced the structure and operation scheme of TPUs.\n",
        "2. Measured the inference performance of TPU, GPU and CPU on 2 LSTM models, 2 MLP models and 2 CNN models.\n",
        "3. Compared the performances of TPU, GPU and CPU from different aspects, including response time, throughput, cost-performance and energy proportionality.\n",
        "4. Use simulation to predict the potential improvements of TPU design."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE2n5UQHbuZ-"
      },
      "source": [
        "---\n",
        "### Q3 Comprehension (15 Points):\n",
        "- What is a Tensor Processing Unit (TPU) and how does it differ from traditional CPUs and GPUs in terms of design and purpose?\n",
        "- Why is there a need for specialized hardware like TPUs in modern data centers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O7k2DbXcNp0"
      },
      "source": [
        "### A3:\n",
        "\n",
        "\n",
        "\n",
        "*   Question 1:\n",
        "\n",
        "TPU is a custom ASIC designed to accelerate the inference of machine learning models.\n",
        "\n",
        "Regarding the design, comparing to CPU, TPU has large number of coprocesssors to run at the same time while CPU only has a few coprocessors. TPU has large size of memory buffers to access to weight values in a faster speed while CPU only has a smaller number of registers to access immeditely. Comparing to both GPU and CPU, TPU quantize the input values into integers for multiplication while GPU and CPU do floating-point calculation. TPU use special firmware to divid and assign the specific machine learning models to run the full workload of all the cores while GPU and CPU are more generalized for all the tasks and cannot realize full optimization on mahine learning tasks.\n",
        "\n",
        "Regarding the purpose, TPU is specifically for accelerating the inference of deep neural network models, while CPU and GPU are for general-purpose calculations.\n",
        "\n",
        "*   Deep neural networks has shown great capability to improve a wide range of problems, such as speech and image recognition. So just by accelerating deep neural networks, a lot of tasks can be accelerated. Besides, there is great need to achieve fast response time of model inference process during actual datacenter usages, so it makes sense to develop accelerators like TPU to focus on accelerating the inference speed and reduce its energy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnzcxvhWckY5"
      },
      "source": [
        "---\n",
        "### Q4 Technical Deep Dive (15 Points):\n",
        "- Describe the architecture of the TPU. How is it optimized for machine learning workloads?\n",
        "- How does the memory hierarchy of the TPU differ from traditional processors, and why is this significant for tensor computations?\n",
        "- What are systolic arrays, and why are they used in TPUs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3rFNjpcuID"
      },
      "source": [
        "### A4:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRBvFutTc2uh"
      },
      "source": [
        "---\n",
        "### Q5 Evaluation (15 Points):\n",
        "- How does the TPU's performance compare to contemporary CPUs and GPUs for machine learning tasks?\n",
        "- What benchmarks or workloads were used to evaluate the TPU's performance in the datacenter?\n",
        "- Discuss the TPU's performance per watt. Why is energy efficiency crucial in datacenter environments?\n",
        "- What types of machine learning models and tasks are best suited for TPUs?\n",
        "- How have TPUs impacted the training times of large-scale models at Google?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKUL8nhTdNLZ"
      },
      "source": [
        "### A5:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp_FV2bzdV4D"
      },
      "source": [
        "---\n",
        "### Q6 Contextual Understanding (10 Points):\n",
        "- What are some of the challenges faced in deploying TPUs in datacenters?\n",
        "- Are there specific machine learning tasks or models that TPUs might struggle with compared to other hardware?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvpxYhvNdg18"
      },
      "source": [
        "### A6:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxUpnGmtdjfX"
      },
      "source": [
        "---\n",
        "### Q7 Discussion and Critique (10 points):\n",
        "- What are the strengths and weaknesses of the paper's methodology and analysis?\n",
        "- Are there any potential biases or assumptions in the paper that you disagree with or find questionable?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjAQy1qLdvZ7"
      },
      "source": [
        "### A7:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSMCnPg8d_0S"
      },
      "source": [
        "---\n",
        "### Q8 Reflection (10 Points):\n",
        "- How do TPUs fit into the larger trend of custom hardware accelerators for machine learning, such as FPGAs and ASICs?\n",
        "- Discuss the trade-offs between general-purpose hardware (like CPUs) and specialized hardware (like TPUs) in the context of evolving machine learning workloads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBtgEgPXeNR5"
      },
      "source": [
        "### A8:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}